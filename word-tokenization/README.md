# WiseSight Samples with Word Tokenization Label

This directory contains WiseSight samples by tokenized humans. These samples are randomly drawn from the corpus.

For wisesight-160, we draw 40 samples for each label, while 250 samples for wisesight-1000. 

**Remark:** We removed a couple of samples from wiseight-1000 because they look like spam.

Althought we have two sets of data, we recommend to use **wisesight-1000** because it contains more samples.
Hence, its evaluation is more respresentative and reliable.

Because these samples are representative of real word content, we believe having these annotaed samples will allow the community to robustly evaluate tokenization algorithms.

## Acknowledgement

The annotation was done by several people, including Nitchakarn Chantarapratin, Pattarawat Chormai, Ponrawee Prasertsom, Jitkapat Sawatphol, Nozomi Yamada, and [Dr.Attapol Rutherford][ate].

[ate]: https://attapol.github.io/index.html